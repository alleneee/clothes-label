# æ¨¡å‹è®­ç»ƒå®Œæ•´æŒ‡å—

æœ¬æŒ‡å—æ¶µç›–äº†ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬å•GPUã€å¤šGPUè®­ç»ƒå’Œå„ç§é«˜çº§åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰
```bash
# ä¸€é”®åˆ›å»ºcondaç¯å¢ƒå¹¶å®‰è£…æ‰€æœ‰ä¾èµ–
bash install.sh
```

å®‰è£…å®Œæˆåä¼šè‡ªåŠ¨åˆ›å»ºä»¥ä¸‹å¯åŠ¨è„šæœ¬ï¼š
- `activate.sh` - æ¿€æ´»ç¯å¢ƒ
- `start_train.sh` - å¼€å§‹è®­ç»ƒ
- `start_api.sh` - å¯åŠ¨APIæœåŠ¡
- `start_jupyter.sh` - å¯åŠ¨Jupyter

#### æ‰‹åŠ¨å®‰è£…ï¼ˆå¯é€‰ï¼‰
```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n model-train python=3.11 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate model-train

# å®‰è£…PyTorch (è‡ªåŠ¨æ£€æµ‹GPU/CPU)
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¼€å‘å·¥å…·
pip install jupyter ipykernel tensorboard
```

### 2. æ•°æ®å‡†å¤‡

#### æ–¹æ³•A: æ ‡å‡†ç›®å½•ç»“æ„ï¼ˆæ¨èï¼‰
```
datasets/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ ç±»åˆ«1/
â”‚   â”‚   â””â”€â”€ ç±»åˆ«2/
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ ç±»åˆ«1/
â”‚   â”‚   â””â”€â”€ ç±»åˆ«2/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ ç±»åˆ«1/
â”‚       â””â”€â”€ ç±»åˆ«2/
```

#### æ–¹æ³•B: è‡ªåŠ¨æ‹†åˆ†
```
datasets/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ ç±»åˆ«1/    # æ‰€æœ‰ç±»åˆ«1çš„å›¾ç‰‡
â”‚   â””â”€â”€ ç±»åˆ«2/    # æ‰€æœ‰ç±»åˆ«2çš„å›¾ç‰‡
```

#### æ–¹æ³•C: åµŒå¥—ç»“æ„ï¼ˆæ”¯æŒç»†ç²’åº¦åˆ†ç±»ï¼‰
```
datasets/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ è¡£æœ/
â”‚   â”‚   â”œâ”€â”€ æ­£é¢å›¾/
â”‚   â”‚   â”œâ”€â”€ èƒŒé¢å›¾/
â”‚   â”‚   â””â”€â”€ ä¾§é¢å›¾/
â”‚   â””â”€â”€ è£¤å­/
â”‚       â”œâ”€â”€ æ­£é¢å›¾/
â”‚       â””â”€â”€ èƒŒé¢å›¾/
```

#### æ•°æ®å‡†å¤‡å·¥å…·
```bash
# è‡ªåŠ¨è§£æå’Œæ‹†åˆ†æ•°æ®é›†
python tools/auto_parse_dataset.py your_dataset

# æ‰‹åŠ¨è®¾ç½®æ•°æ®é›†
python tools/setup_dataset.py --mode create_structure
```

### 3. é…ç½®æ–‡ä»¶

ç¼–è¾‘ `configs/config.yaml`ï¼š

```yaml
# æ•°æ®é…ç½®
data:
  data_dir: "datasets/main"
  batch_size: 32
  image_size: 224
  num_workers: 4
  auto_split: true
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1
  nested_structure: false        # æ˜¯å¦ä½¿ç”¨åµŒå¥—ç»“æ„
  classification_mode: "main_category"  # åˆ†ç±»æ¨¡å¼

# æ¨¡å‹é…ç½®
model:
  name: "efficientnetv2_s"       # æ¨¡å‹ç±»å‹
  learning_rate: 1e-4
  weight_decay: 1e-4

# è®­ç»ƒé…ç½®
training:
  max_epochs: 100
  patience: 10
  mixed_precision: true          # æ··åˆç²¾åº¦è®­ç»ƒ
  gradient_clip_val: 1.0

# æ—¥å¿—é…ç½®
logging:
  log_dir: "lightning_logs"
  experiment_name: "product_classification"
```

## ğŸ¯ å¼€å§‹è®­ç»ƒ

### å•GPU/CPUè®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python train.py --config configs/config.yaml

# å¯ç”¨ç¡¬ä»¶è‡ªåŠ¨ä¼˜åŒ–
python train.py --config configs/config.yaml --auto-optimize

# ç¦ç”¨å¤šGPUï¼ˆå¼ºåˆ¶å•GPUï¼‰
python train.py --config configs/config.yaml --no-multi-gpu
```

### å¤šGPUè®­ç»ƒï¼ˆæ¨èï¼‰
```bash
# è‡ªåŠ¨å¤šGPUè®­ç»ƒï¼ˆæ¨èï¼‰
python train.py --config configs/config.yaml

# æŒ‡å®šGPUæ•°é‡
python train.py --config configs/config.yaml --gpus 2

# å¼ºåˆ¶ä½¿ç”¨DDPç­–ç•¥
python train.py --config configs/config.yaml --strategy ddp

# ä½¿ç”¨ä¸“é—¨çš„å¤šGPUè„šæœ¬
python scripts/train_multi_gpu.py --config configs/config.yaml
```

### å¾®è°ƒè®­ç»ƒ
```bash
# å¯¹é”™è¯¯æ ·æœ¬è¿›è¡Œå¾®è°ƒ
python finetune/corrected_fine_tune.py --config configs/config.yaml

# å¿«é€Ÿå¾®è°ƒ
python finetune/quick_corrected_fine_tune.py --config configs/config.yaml
```

## âš™ï¸ é«˜çº§åŠŸèƒ½

### 1. ç¡¬ä»¶è‡ªåŠ¨ä¼˜åŒ–
ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®å¹¶ä¼˜åŒ–è®­ç»ƒå‚æ•°ï¼š
- è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°
- ä¼˜åŒ–æ•°æ®åŠ è½½è¿›ç¨‹æ•°
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- é€‰æ‹©æœ€ä¼˜çš„è®­ç»ƒç­–ç•¥

### 2. å¤šGPUè®­ç»ƒç­–ç•¥

| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|----------|------|------|
| DDP | 2+GPUï¼Œæ¨è | æœ€é«˜æ•ˆï¼Œæ”¯æŒå¤šæœº | å†…å­˜å ç”¨ç¨é«˜ |
| DataParallel | å•æœºå¤šå¡ | å®ç°ç®€å• | å­˜åœ¨GPU0ç“¶é¢ˆ |
| DeepSpeed | å¤§æ¨¡å‹ | å†…å­˜ä¼˜åŒ– | éœ€è¦é¢å¤–å®‰è£… |

### 3. æ•°æ®ä¸å‡è¡¡å¤„ç†
```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨
imbalance:
  enabled: true
  strategy: "weighted_loss"      # æˆ– "oversample", "undersample"
  auto_detect: true
```

### 4. åˆ†ç±»æ¨¡å¼é€‰æ‹©

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `main_category` | æŒ‰ä¸»ç±»åˆ«åˆ†ç±» | å•†å“å¤§ç±»åˆ†ç±» |
| `sub_category` | æŒ‰å­ç±»åˆ«åˆ†ç±» | ç»†ç²’åº¦åˆ†ç±» |
| `image_type` | æŒ‰å›¾åƒç±»å‹åˆ†ç±» | è§’åº¦/è§†å›¾åˆ†ç±» |

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### TensorBoardç›‘æ§
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir lightning_logs

# æµè§ˆå™¨è®¿é—®
http://localhost:6006
```

### GPUç›‘æ§
```bash
# å®æ—¶ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æµ‹è¯•å¤šGPUåŠŸèƒ½
python tests/test_multi_gpu.py
```

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³

### å†…å­˜ä¸è¶³
```yaml
# å‡å°æ‰¹æ¬¡å¤§å°
training:
  batch_size: 16

data:
  num_workers: 2
```

### è®­ç»ƒé€Ÿåº¦æ…¢
```yaml
# å¯ç”¨ä¼˜åŒ–é€‰é¡¹
training:
  mixed_precision: true

data:
  pin_memory: true
  num_workers: 8
```

### ç²¾åº¦ä¸å¤Ÿé«˜
```yaml
# ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
model:
  name: "efficientnetv2_l"
  learning_rate: 5e-5

training:
  max_epochs: 200
```

### AVIFæ ¼å¼æ”¯æŒ
```bash
# å®‰è£…AVIFæ”¯æŒ
python tools/install_avif_support.py

# è½¬æ¢AVIFåˆ°JPEG
python tools/avif_converter.py --input_dir datasets/main --output_dir datasets/converted
```

## ğŸ¯ æ¨ç†é¢„æµ‹

### å‘½ä»¤è¡Œé¢„æµ‹
```bash
# å•å¼ å›¾ç‰‡é¢„æµ‹
python core/predict.py --model_path model/best_model.ckpt --mode single --image_path test.jpg

# æ‰¹é‡é¢„æµ‹
python core/predict.py --model_path model/best_model.ckpt --mode batch --image_folder test_images/

# Webç•Œé¢
python core/predict.py --model_path model/best_model.ckpt --mode web
```

### FastAPIæœåŠ¡ï¼ˆæ¨èï¼‰
```bash
# å¯åŠ¨APIæœåŠ¡
python scripts/start_api.py

# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
python scripts/start_api.py --dev

# ç”Ÿäº§æ¨¡å¼ï¼ˆå¤šè¿›ç¨‹ï¼‰
python scripts/start_api.py --prod

# è‡ªå®šä¹‰é…ç½®
python scripts/start_api.py --host 0.0.0.0 --port 8000 --model-path model/best_model.ckpt
```

### APIä½¿ç”¨ç¤ºä¾‹
```python
import requests
import base64

# è¯»å–å›¾åƒæ–‡ä»¶
with open('test.jpg', 'rb') as f:
    image_data = base64.b64encode(f.read()).decode('utf-8')

# å‘é€é¢„æµ‹è¯·æ±‚
response = requests.post('http://localhost:8000/predict/single',
    json={
        'image_data': image_data,
        'return_probabilities': True
    }
)

result = response.json()
print(f"é¢„æµ‹ç±»åˆ«: {result['data']['predicted_class']}")
print(f"ç½®ä¿¡åº¦: {result['data']['confidence']}")
```

### APIåŠŸèƒ½
- **å•å¼ é¢„æµ‹**: `POST /predict/single` - Base64å›¾åƒæ•°æ®
- **æ‰¹é‡é¢„æµ‹**: `POST /predict/batch` - æœ€å¤š50å¼ å›¾åƒ
- **æ–‡ä»¶ä¸Šä¼ **: `POST /predict/upload` - ç›´æ¥ä¸Šä¼ å›¾åƒæ–‡ä»¶
- **å¥åº·æ£€æŸ¥**: `GET /system/health` - æœåŠ¡çŠ¶æ€æ£€æŸ¥
- **æ¨¡å‹ä¿¡æ¯**: `GET /system/model-info` - è·å–æ¨¡å‹è¯¦æƒ…
- **APIæ–‡æ¡£**: `http://localhost:8000/docs` - Swagger UI

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–
- ä½¿ç”¨SSDå­˜å‚¨æ•°æ®é›†
- é€‚å½“å¢åŠ  `num_workers`
- å¯ç”¨ `pin_memory`

### 2. è®­ç»ƒä¼˜åŒ–
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- ä½¿ç”¨åˆé€‚çš„æ‰¹æ¬¡å¤§å°
- å¤šGPUè®­ç»ƒä½¿ç”¨DDPç­–ç•¥

### 3. æ¨¡å‹é€‰æ‹©
- å¿«é€ŸåŸå‹ï¼š`efficientnetv2_s`
- å¹³è¡¡æ€§èƒ½ï¼š`efficientnetv2_m`
- è¿½æ±‚ç²¾åº¦ï¼š`efficientnetv2_l`

## ğŸ› ï¸ å·¥å…·è„šæœ¬

```bash
# æ•°æ®é›†åˆ†æ
python tools/quick_dataset_analysis.py

# æ¸…ç†æŸåå›¾ç‰‡
python tools/clean_corrupted_images.py

# ä¿®å¤æ•°æ®é›†æ ¼å¼
python tools/fix_dataset_format.py

# å¿«é€Ÿè®¾ç½®
python scripts/quick_setup.py
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **æ•°æ®å‡†å¤‡**ï¼šç¡®ä¿æ•°æ®é›†ç»“æ„æ­£ç¡®ï¼Œå›¾ç‰‡è´¨é‡è‰¯å¥½
2. **é…ç½®è°ƒä¼˜**ï¼šæ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œå­¦ä¹ ç‡
3. **ç›‘æ§è®­ç»ƒ**ï¼šä½¿ç”¨TensorBoardç›‘æ§è®­ç»ƒè¿‡ç¨‹
4. **å¤šGPUè®­ç»ƒ**ï¼šä¼˜å…ˆä½¿ç”¨DDPç­–ç•¥
5. **æ¨¡å‹ä¿å­˜**ï¼šå®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼Œé˜²æ­¢è®­ç»ƒä¸­æ–­
6. **æµ‹è¯•éªŒè¯**ï¼šè®­ç»ƒå®Œæˆååœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯æ€§èƒ½

---

è¿™ä¸ªæŒ‡å—æ¶µç›–äº†æ¨¡å‹è®­ç»ƒçš„æ‰€æœ‰é‡è¦æ–¹é¢ã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶è®¾ç½®æˆ–æŸ¥çœ‹è®­ç»ƒæ—¥å¿—è·å–æ›´å¤šä¿¡æ¯ã€‚
