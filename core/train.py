"""
PyTorch Lightning å•†å“åˆ†ç±»è®­ç»ƒè„šæœ¬
ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒPython 3.11ç‰¹æ€§å’ŒCUDA 12.4
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
import timm
import argparse
import yaml
from pathlib import Path
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# é…ç½®ä¸­æ–‡å­—ä½“å’Œé™é»˜è­¦å‘Š
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=UserWarning, module='seaborn')
from typing import Dict, Any, Optional, Union, Tuple
import sys
import os
from datetime import datetime

# Python 3.11æ€§èƒ½ä¼˜åŒ–
if sys.version_info >= (3, 11):
    # å¯ç”¨Python 3.11çš„æ€§èƒ½ä¼˜åŒ–
    import gc
    gc.set_threshold(700, 10, 10)  # ä¼˜åŒ–åƒåœ¾å›æ”¶

try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºåŒ…çš„ä¸€éƒ¨åˆ†è¿è¡Œæ—¶ï¼‰
    from .hardware_optimizer import HardwareDetector, ConfigOptimizer, DynamicConfigAdjuster
except ImportError:
    # å°è¯•ç»å¯¹å¯¼å…¥ï¼ˆå½“ç›´æ¥è¿è¡Œæ—¶ï¼‰
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from core.hardware_optimizer import HardwareDetector, ConfigOptimizer, DynamicConfigAdjuster


class ProductClassifier(pl.LightningModule):
    """å•†å“åˆ†ç±»å™¨ Lightning æ¨¡å—"""

    def __init__(self, config, enable_dynamic_adjustment=False):
        super().__init__()
        self.save_hyperparameters()

        # ä»é…ç½®åŠ è½½å‚æ•°
        model_config = config['model']
        self.num_classes = model_config['num_classes']
        self.model_name = model_config['name']
        self.learning_rate = model_config['learning_rate']
        self.weight_decay = model_config['weight_decay']
        # è·å–ç±»åˆ«åç§°ï¼Œæ”¯æŒä»checkpointåŠ è½½æ—¶æ²¡æœ‰ç±»åˆ«åç§°çš„æƒ…å†µ
        self.class_names = config.get('classes', {}).get('names', [])

        # åŠ¨æ€é…ç½®è°ƒæ•´
        self.enable_dynamic_adjustment = enable_dynamic_adjustment
        if enable_dynamic_adjustment:
            self.dynamic_adjuster = DynamicConfigAdjuster(config)
            self.batch_times = []
        
        # åˆ›å»ºæ¨¡å‹
        pretrained = config.get('model', {}).get('pretrained', True)  # ä»é…ç½®æ–‡ä»¶è¯»å–pretrainedè®¾ç½®
        use_timm_pretrained = pretrained and not model_config.get('local_pretrained_path')
        self.model = timm.create_model(
            self.model_name,
            pretrained=use_timm_pretrained,
            num_classes=self.num_classes,
            drop_rate=model_config.get('drop_rate', 0.2),
            drop_path_rate=model_config.get('drop_path_rate', 0.2)
        )

        local_pretrained_path = model_config.get('local_pretrained_path')
        if pretrained and local_pretrained_path:
            try:
                if os.path.exists(local_pretrained_path):
                    print(f"ğŸ“‚ ä»æœ¬åœ°åŠ è½½é¢„è®­ç»ƒæƒé‡: {local_pretrained_path}")
                    checkpoint = torch.load(local_pretrained_path, map_location='cpu')
                    state_dict = checkpoint.get('state_dict', checkpoint)
                    self.model.load_state_dict(state_dict, strict=False)
                    print("âœ… æœ¬åœ°é¢„è®­ç»ƒæƒé‡åŠ è½½å®Œæˆ")
                else:
                    print(f"âš ï¸ æœ¬åœ°é¢„è®­ç»ƒæƒé‡ä¸å­˜åœ¨: {local_pretrained_path}")
            except Exception as e:
                print(f"âš ï¸ æœ¬åœ°é¢„è®­ç»ƒæƒé‡åŠ è½½å¤±è´¥: {e}")
        
        # torch.compile()ä¼˜åŒ– - PyTorch 2.0æ€§èƒ½æå‡
        performance_config = config.get('performance', {})
        if performance_config.get('enable_torch_compile', True):
            try:
                # æ£€æŸ¥PyTorchç‰ˆæœ¬å’Œtorch.compileæ”¯æŒ
                if hasattr(torch, 'compile') and hasattr(torch, '__version__') and torch.__version__ >= '2.0.0':
                    compile_mode = performance_config.get('torch_compile_mode', 'reduce-overhead')
                    
                    # æ”¯æŒçš„ç¼–è¯‘æ¨¡å¼
                    valid_modes = ['default', 'reduce-overhead', 'max-autotune']
                    if compile_mode not in valid_modes:
                        compile_mode = 'reduce-overhead'
                    
                    print(f"ğŸš€ å¯ç”¨torch.compile()ä¼˜åŒ–ï¼Œæ¨¡å¼: {compile_mode}")
                    self.model = torch.compile(self.model, mode=compile_mode)
                    print("âœ… torch.compile()ä¼˜åŒ–å·²å¯ç”¨")
                else:
                    if hasattr(torch, '__version__'):
                        print(f"âš ï¸ PyTorchç‰ˆæœ¬ {torch.__version__} ä¸æ”¯æŒtorch.compile()ï¼Œéœ€è¦2.0.0+")
                    else:
                        print("âš ï¸ å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒtorch.compile()")
            except Exception as e:
                print(f"âš ï¸ torch.compile()å¯ç”¨å¤±è´¥: {e}")
                print("ğŸ“ ç»§ç»­ä½¿ç”¨æœªç¼–è¯‘çš„æ¨¡å‹")
        else:
            print("ğŸ“ torch.compile()ä¼˜åŒ–å·²ç¦ç”¨")
        
        # æŸå¤±å‡½æ•° (å°†åœ¨è®­ç»ƒæ—¶æ ¹æ®æ•°æ®ä¸å‡è¡¡æƒ…å†µåŠ¨æ€è®¾ç½®)
        self.criterion = nn.CrossEntropyLoss()
        self.use_balanced_loss = False
        
        # ç”¨äºæ”¶é›†é¢„æµ‹ç»“æœ
        self.validation_step_outputs = []
        self.test_step_outputs = []

    def set_balanced_loss(self, balanced_loss):
        """è®¾ç½®å¹³è¡¡çš„æŸå¤±å‡½æ•°"""
        if balanced_loss is not None:
            self.criterion = balanced_loss
            self.use_balanced_loss = True
            print("âœ… å·²å¯ç”¨å¹³è¡¡æŸå¤±å‡½æ•°")
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        import time
        start_time = time.time()

        # æ”¯æŒå­—å…¸å’Œå…ƒç»„ä¸¤ç§æ ¼å¼
        if isinstance(batch, dict):
            # å­—å…¸æ ¼å¼: {'image': x, 'label': y}
            x, y = batch['image'], batch['label']
            logits = self(x)
            loss = self.criterion(logits, y)
            
            # è®¡ç®—å‡†ç¡®ç‡
            preds = torch.argmax(logits, dim=1)
            acc = torch.sum(preds == y).float() / len(y)
        elif len(batch) == 4:
            # Mixup/CutMix: (x, y_a, y_b, lam)
            x, y_a, y_b, lam = batch
            logits = self(x)
            
            # è®¡ç®—æ··åˆæŸå¤±
            loss_a = self.criterion(logits, y_a)
            loss_b = self.criterion(logits, y_b)
            loss = lam * loss_a + (1 - lam) * loss_b
            
            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆä½¿ç”¨ä¸»è¦æ ‡ç­¾ï¼‰
            preds = torch.argmax(logits, dim=1)
            acc = torch.sum(preds == y_a).float() / len(y_a)
        else:
            # æ­£å¸¸æ‰¹æ¬¡: (x, y)
            x, y = batch
            logits = self(x)
            loss = self.criterion(logits, y)
            
            # è®¡ç®—å‡†ç¡®ç‡
            preds = torch.argmax(logits, dim=1)
            acc = torch.sum(preds == y).float() / len(y)

        # è®°å½•æŒ‡æ ‡
        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)

        # æ€§èƒ½ç›‘æ§å’ŒåŠ¨æ€è°ƒæ•´
        if self.enable_dynamic_adjustment:
            batch_time = time.time() - start_time
            self.batch_times.append(batch_time)

            # æ¯100ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡
            if batch_idx % 100 == 0 and len(self.batch_times) >= 10:
                avg_batch_time = sum(self.batch_times[-10:]) / 10

                # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
                if torch.cuda.is_available():
                    memory_usage = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()
                    gpu_utilization = None  # éœ€è¦nvidia-ml-pyæ¥è·å–
                else:
                    import psutil
                    memory_usage = psutil.virtual_memory().percent / 100
                    gpu_utilization = None

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´
                if self.dynamic_adjuster.monitor_training_performance(
                    self.current_epoch, avg_batch_time, memory_usage, gpu_utilization
                ):
                    print(f"\nğŸ”§ æ£€æµ‹åˆ°æ€§èƒ½é—®é¢˜ï¼Œæ­£åœ¨è°ƒæ•´é…ç½®...")
                    new_config = self.dynamic_adjuster.adjust_config()
                    # æ³¨æ„ï¼šå®é™…çš„æ‰¹æ¬¡å¤§å°è°ƒæ•´éœ€è¦é‡å¯è®­ç»ƒï¼Œè¿™é‡Œåªæ˜¯è®°å½•

        return loss
    
    def validation_step(self, batch, batch_idx):
        # æ”¯æŒå­—å…¸å’Œå…ƒç»„ä¸¤ç§æ ¼å¼
        if isinstance(batch, dict):
            x, y = batch['image'], batch['label']
        else:
            x, y = batch
        
        logits = self(x)
        loss = self.criterion(logits, y)
        
        preds = torch.argmax(logits, dim=1)
        acc = torch.sum(preds == y).float() / len(y)
        
        # è®°å½•æŒ‡æ ‡
        self.log('val_loss', loss, on_epoch=True, prog_bar=True)
        self.log('val_acc', acc, on_epoch=True, prog_bar=True)
        
        # æ”¶é›†é¢„æµ‹ç»“æœ
        self.validation_step_outputs.append({
            'preds': preds.cpu(),
            'targets': y.cpu(),
            'loss': loss.cpu()
        })
        
        return {'val_loss': loss, 'val_acc': acc}
    
    def on_validation_epoch_end(self):
        """éªŒè¯è½®æ¬¡ç»“æŸæ—¶è®¡ç®—è¯¦ç»†æŒ‡æ ‡"""
        if not self.validation_step_outputs:
            return
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ
        all_preds = torch.cat([x['preds'] for x in self.validation_step_outputs])
        all_targets = torch.cat([x['targets'] for x in self.validation_step_outputs])
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        for i, class_name in enumerate(self.class_names):
            class_mask = all_targets == i
            if class_mask.sum() > 0:
                class_acc = (all_preds[class_mask] == all_targets[class_mask]).float().mean()
                self.log(f'val_acc_{class_name}', class_acc, on_epoch=True)
        
        # æ¸…ç©ºè¾“å‡º
        self.validation_step_outputs.clear()
    
    def test_step(self, batch, batch_idx):
        # æ”¯æŒå­—å…¸å’Œå…ƒç»„ä¸¤ç§æ ¼å¼
        if isinstance(batch, dict):
            x, y = batch['image'], batch['label']
        else:
            x, y = batch
        
        logits = self(x)
        loss = self.criterion(logits, y)
        
        preds = torch.argmax(logits, dim=1)
        acc = torch.sum(preds == y).float() / len(y)
        
        self.log('test_loss', loss, on_epoch=True)
        self.log('test_acc', acc, on_epoch=True)
        
        # æ”¶é›†é¢„æµ‹ç»“æœ
        self.test_step_outputs.append({
            'preds': preds.cpu(),
            'targets': y.cpu(),
            'probs': F.softmax(logits, dim=1).cpu()
        })
        
        return {'test_loss': loss, 'test_acc': acc}
    
    def on_test_epoch_end(self):
        """æµ‹è¯•ç»“æŸæ—¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        if not self.test_step_outputs:
            return
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ
        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])
        all_targets = torch.cat([x['targets'] for x in self.test_step_outputs])
        
        # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        print("\n" + "="*50)
        print("æµ‹è¯•é›†åˆ†ç±»æŠ¥å‘Š")
        print("="*50)
        print(classification_report(
            all_targets.numpy(),
            all_preds.numpy(),
            target_names=self.class_names
        ))
        
        # ç”Ÿæˆæ··æ·†çŸ©é˜µ
        cm = confusion_matrix(all_targets.numpy(), all_preds.numpy())
        self._plot_confusion_matrix(cm)
        
    def _plot_confusion_matrix(self, cm):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=self.class_names, yticklabels=self.class_names,
                    cbar_kws={'label': 'Count'})
        plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.tight_layout()
        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

    def configure_optimizers(self):
        """é…ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.learning_rate,
            weight_decay=self.weight_decay
        )
        
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=100,
            eta_min=1e-6
        )
        
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'monitor': 'val_loss'
            }
        }
    
    def predict_single(self, image_path: str):
        """å•å¼ å›¾ç‰‡é¢„æµ‹"""
        from PIL import Image
        from torchvision import transforms
        
        # æ•°æ®é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
        image = Image.open(image_path)
        # ä¿®å¤PILé€æ˜åº¦è­¦å‘Šï¼šå¦‚æœæ˜¯è°ƒè‰²æ¿å›¾åƒä¸”æœ‰é€æ˜åº¦ï¼Œå…ˆè½¬æ¢ä¸ºRGBAå†è½¬RGB
        if image.mode == 'P' and 'transparency' in image.info:
            image = image.convert('RGBA')
        image = image.convert('RGB')
        image_tensor = transform(image).unsqueeze(0)
        
        # é¢„æµ‹
        self.eval()
        with torch.no_grad():
            if torch.cuda.is_available():
                image_tensor = image_tensor.cuda()
            
            logits = self(image_tensor)
            probs = F.softmax(logits, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_class].item()
        
        return {
            'predicted_class': self.class_names[pred_class],
            'predicted_index': pred_class,
            'confidence': confidence,
            'probabilities': {
                self.class_names[i]: probs[0][i].item()
                for i in range(len(self.class_names))
            }
        }


def load_config(config_path: str = 'configs/config.yaml'):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def train_model(config, auto_optimize=True, multi_gpu=True, force_strategy=None, ckpt_path=None):
    """
    è®­ç»ƒæ¨¡å‹

    Args:
        config: è®­ç»ƒé…ç½®
        auto_optimize: æ˜¯å¦å¯ç”¨ç¡¬ä»¶è‡ªåŠ¨ä¼˜åŒ–
        multi_gpu: æ˜¯å¦å¯ç”¨å¤šGPUè®­ç»ƒ
        force_strategy: å¼ºåˆ¶ä½¿ç”¨çš„å¤šGPUç­–ç•¥ ('ddp', 'dp', 'deepspeed')
        ckpt_path: checkpointæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæ¢å¤è®­ç»ƒ
    """

    # ç¡¬ä»¶æ£€æµ‹å’Œé…ç½®ä¼˜åŒ–
    if auto_optimize:
        print("ğŸ” æ£€æµ‹ç¡¬ä»¶é…ç½®å¹¶ä¼˜åŒ–å‚æ•°...")
        hardware_detector = HardwareDetector()
        hardware_detector.print_hardware_info()

        optimizer = ConfigOptimizer(hardware_detector)
        original_config = config.copy()
        config = optimizer.optimize_training_config(config)

        # æ‰“å°ä¼˜åŒ–æŠ¥å‘Š
        report = optimizer.generate_optimization_report(original_config, config)
        print(f"\n{report}")

        # ä¿å­˜ä¼˜åŒ–åçš„é…ç½®
        optimized_config_path = f"config_optimized_{hardware_detector.get_hardware_tier()}.yaml"
        with open(optimized_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
        print(f"\nğŸ’¾ ä¼˜åŒ–åé…ç½®å·²ä¿å­˜: {optimized_config_path}")

    # å¤šGPUé…ç½®
    multi_gpu_trainer = None
    if multi_gpu:
        print("ğŸš€ åˆå§‹åŒ–å¤šGPUè®­ç»ƒé…ç½®...")
        multi_gpu_trainer = MultiGPUTrainer(config, force_strategy=force_strategy)
        # æ›´æ–°æ•°æ®æ¨¡å—é…ç½®ä»¥é€‚åº”å¤šGPU
        if 'data' not in config:
            config['data'] = {}
        config['data'] = multi_gpu_trainer.update_dataloader_config(config.get('data', {}))
        config['data']['batch_size'] = multi_gpu_trainer.gpu_config['batch_size_per_gpu']

        print(f"âœ… å¤šGPUé…ç½®å®Œæˆ:")
        print(f"   - GPUæ•°é‡: {multi_gpu_trainer.gpu_config['devices']}")
        print(f"   - è®­ç»ƒç­–ç•¥: {multi_gpu_trainer.gpu_config['strategy']}")
        print(f"   - æ¯GPUæ‰¹æ¬¡å¤§å°: {multi_gpu_trainer.gpu_config['batch_size_per_gpu']}")
        print(f"   - æ€»æ‰¹æ¬¡å¤§å°: {multi_gpu_trainer.gpu_config['total_batch_size']}")
        print(f"   - æ··åˆç²¾åº¦: {'å¯ç”¨' if multi_gpu_trainer.gpu_config['precision'] == 16 else 'ç¦ç”¨'}")
    else:
        print("ğŸ“± ä½¿ç”¨å•GPU/CPUè®­ç»ƒæ¨¡å¼")

    # åˆ›å»ºæ•°æ®æ¨¡å—
    data_module = ProductDataModule(
        data_dir=config['data']['data_dir'],
        batch_size=config['data']['batch_size'],
        image_size=config['data']['image_size'],
        num_workers=config['data']['num_workers'],
        auto_split=config['data']['auto_split'],
        train_split=config['data']['train_split'],
        val_split=config['data']['val_split'],
        test_split=config['data']['test_split'],
        classification_mode=config['data'].get('classification_mode', 'main_category'),
        nested_structure=config['data'].get('nested_structure', False),
        imbalance_config=config.get('imbalance', {})
    )
    
    # å‡†å¤‡æ•°æ®
    data_module.prepare_data()
    data_module.setup()
    data_module.print_data_info()
    
    # æ›´æ–°é…ç½®ä¸­çš„ç±»åˆ«ä¿¡æ¯
    config['model']['num_classes'] = data_module.num_classes
    if 'classes' not in config:
        config['classes'] = {}
    config['classes']['names'] = data_module.class_names
    
    # åˆ›å»ºæ¨¡å‹
    enable_dynamic = auto_optimize and config.get('advanced', {}).get('enable_dynamic_adjustment', False)
    model = ProductClassifier(config, enable_dynamic_adjustment=enable_dynamic)

    # è®¾ç½®å¹³è¡¡çš„æŸå¤±å‡½æ•°
    balanced_loss = data_module.get_balanced_loss()
    if balanced_loss is not None:
        model.set_balanced_loss(balanced_loss)
    
    # è®¾ç½®å›è°ƒå‡½æ•°
    checkpoint_config = config.get('checkpointing', {})
    
    # ç”ŸæˆåŒ…å«æ—¥æœŸçš„æ–‡ä»¶å
    current_date = datetime.now().strftime("%Y%m%d")
    base_filename = checkpoint_config.get('filename', 'best-{epoch:02d}-{val_acc:.3f}')
    filename_with_date = f"{current_date}-{base_filename}"
    
    callbacks = [
        ModelCheckpoint(
            monitor=checkpoint_config.get('monitor', 'val_acc'),
            mode=checkpoint_config.get('mode', 'max'),
            save_top_k=checkpoint_config.get('save_top_k', 1),
            filename=filename_with_date,
            save_last=checkpoint_config.get('save_last', True),
            dirpath=checkpoint_config.get('dirpath', None),  # ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
            save_weights_only=checkpoint_config.get('save_weights_only', False),
            auto_insert_metric_name=False
        ),
        EarlyStopping(
            monitor='val_acc',
            mode='max',
            patience=config['training']['patience'],
            verbose=True
        ),
        LearningRateMonitor(logging_interval='epoch')
    ]
    
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = TensorBoardLogger(
        config['logging']['log_dir'], 
        name=config['logging']['experiment_name']
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨ - æ”¯æŒå¤šGPU
    if multi_gpu_trainer:
        trainer = multi_gpu_trainer.create_trainer(callbacks=callbacks, logger=logger)
    else:
        # å•GPU/CPUè®­ç»ƒå™¨
        trainer = pl.Trainer(
            max_epochs=config['training']['max_epochs'],
            callbacks=callbacks,
            logger=logger,
            accelerator='auto',
            devices='auto',
            precision=16 if config['training']['mixed_precision'] else 32,
            log_every_n_steps=10,
            val_check_interval=0.5,
            gradient_clip_val=config['training']['gradient_clip_val']
        )
    
    # å¼€å§‹è®­ç»ƒ
    if ckpt_path:
        print(f"ä»checkpointæ¢å¤è®­ç»ƒ: {ckpt_path}")
        trainer.fit(model, data_module, ckpt_path=ckpt_path)
    else:
        print("å¼€å§‹æ–°çš„è®­ç»ƒ...")
        trainer.fit(model, data_module)
    
    # æ‰¾åˆ°å¹¶é‡å‘½åæœ€ä½³æ¨¡å‹ï¼ˆæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼‰
    print("æ­£åœ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹...")
    best_model_path = find_and_rename_best_model()

    # æµ‹è¯•æœ€ä½³æ¨¡å‹ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œæµ‹è¯•ï¼‰
    should_test = True
    try:
        import torch.distributed as dist
        if dist.is_available() and dist.is_initialized():
            should_test = (dist.get_rank() == 0)
    except ImportError:
        pass
    
    if should_test:
        print("æµ‹è¯•æœ€ä½³æ¨¡å‹...")
        try:
            if best_model_path and os.path.exists(best_model_path):
                trainer.test(model, data_module, ckpt_path=best_model_path)
                print(f"âœ… æœ€ä½³æ¨¡å‹æµ‹è¯•å®Œæˆ: {best_model_path}")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹checkpointï¼Œè·³è¿‡æµ‹è¯•")
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            print("è®­ç»ƒå·²å®Œæˆï¼Œä½†æµ‹è¯•é˜¶æ®µå‡ºç°é—®é¢˜")
    else:
        print(f"â³ [Rank {dist.get_rank()}] è·³è¿‡æµ‹è¯•é˜¶æ®µï¼ˆä»…åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼‰")

    print("è®­ç»ƒå®Œæˆ!")
    if best_model_path:
        print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")
    else:
        print("æœ€ä½³æ¨¡å‹è·¯å¾„æœªæ‰¾åˆ°")
    
    return model, trainer


def find_and_rename_best_model():
    """
    æ‰¾åˆ°å‡†ç¡®ç‡æœ€é«˜çš„checkpointæ–‡ä»¶å¹¶é‡å‘½åä¸ºbestæ¨¡å‹
    æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼Œåªåœ¨ä¸»è¿›ç¨‹ï¼ˆrank 0ï¼‰ä¸­æ‰§è¡Œæ¨¡å‹æŸ¥æ‰¾å’Œé‡å‘½å

    Returns:
        str: æœ€ä½³æ¨¡å‹çš„è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    import glob
    import shutil
    import time
    
    # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­
    is_distributed = False
    is_main_process = True
    
    try:
        import torch.distributed as dist
        if dist.is_available() and dist.is_initialized():
            is_distributed = True
            is_main_process = (dist.get_rank() == 0)
    except ImportError:
        pass
    
    checkpoint_dir = "model/checkpoints"
    best_model_path = None
    
    if is_main_process:
        # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œæ¨¡å‹æŸ¥æ‰¾å’Œé‡å‘½å
        print("ğŸ” [ä¸»è¿›ç¨‹] æŸ¥æ‰¾æœ€ä½³æ¨¡å‹...")
        
        # æŸ¥æ‰¾æ‰€æœ‰checkpointæ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§æ–‡ä»¶åæ ¼å¼ï¼‰
        ckpt_patterns = [
            "a10-v2-*.ckpt",
            "best-*.ckpt", 
            "enhanced-clothes-*.ckpt",
            "*.ckpt"
        ]
        
        ckpt_files = []
        for pattern in ckpt_patterns:
            files = glob.glob(os.path.join(checkpoint_dir, pattern))
            ckpt_files.extend(files)
        
        # å»é™¤é‡å¤æ–‡ä»¶
        ckpt_files = list(set(ckpt_files))
        
        if not ckpt_files:
            print("âŒ [ä¸»è¿›ç¨‹] æœªæ‰¾åˆ°ä»»ä½•checkpointæ–‡ä»¶")
            best_model_path = None
        else:
            print(f"ğŸ“ [ä¸»è¿›ç¨‹] æ‰¾åˆ° {len(ckpt_files)} ä¸ªcheckpointæ–‡ä»¶")

            best_acc = 0.0
            best_file = None
            best_epoch = 0

            for ckpt_file in ckpt_files:
                # ä»æ–‡ä»¶åæå–å‡†ç¡®ç‡
                filename = os.path.basename(ckpt_file)
                try:
                    # æ”¯æŒå¤šç§æ–‡ä»¶åæ ¼å¼
                    acc = None
                    epoch = None
                    
                    # æ ¼å¼1: a10-v2-{epoch}-{acc}.ckpt
                    if 'a10-v2-' in filename:
                        parts = filename.replace('.ckpt', '').split('-')
                        if len(parts) >= 4:
                            acc = float(parts[-1])
                            epoch = int(parts[-2])
                    
                    # æ ¼å¼2: best-{epoch}-{acc}.ckpt æˆ– enhanced-clothes-{epoch}-{acc}.ckpt
                    elif '-' in filename and filename.count('-') >= 2:
                        parts = filename.replace('.ckpt', '').split('-')
                        if len(parts) >= 3:
                            try:
                                acc = float(parts[-1])
                                epoch = int(parts[-2])
                            except ValueError:
                                # å¦‚æœæœ€åä¸¤éƒ¨åˆ†ä¸æ˜¯æ•°å­—ï¼Œå°è¯•å…¶ä»–ç»„åˆ
                                for i in range(len(parts)-1, 0, -1):
                                    try:
                                        acc = float(parts[i])
                                        epoch = int(parts[i-1])
                                        break
                                    except ValueError:
                                        continue
                    
                    if acc is not None and epoch is not None:
                        print(f"  ğŸ“„ [ä¸»è¿›ç¨‹] Epoch {epoch}: å‡†ç¡®ç‡ {acc:.3f}")
                        
                        if acc > best_acc:
                            best_acc = acc
                            best_file = ckpt_file
                            best_epoch = epoch
                    else:
                        print(f"  âš ï¸  [ä¸»è¿›ç¨‹] æ— æ³•è§£ææ–‡ä»¶å: {filename}")
                        
                except (ValueError, IndexError) as e:
                    print(f"  âš ï¸  [ä¸»è¿›ç¨‹] æ— æ³•è§£ææ–‡ä»¶å: {filename}, é”™è¯¯: {e}")

            if best_file:
                # åˆ›å»ºæœ€ä½³æ¨¡å‹çš„æ–°è·¯å¾„
                current_date = datetime.now().strftime("%Y%m%d")
                best_model_name = f"best_model_epoch_{best_epoch}_acc_{best_acc:.3f}_{current_date}.ckpt"
                best_model_path = os.path.join(checkpoint_dir, best_model_name)

                try:
                    # ç¡®ä¿checkpointç›®å½•å­˜åœ¨
                    os.makedirs(checkpoint_dir, exist_ok=True)
                    
                    # å¤åˆ¶æœ€ä½³æ¨¡å‹
                    shutil.copy2(best_file, best_model_path)
                    print(f"ğŸ† [ä¸»è¿›ç¨‹] æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_model_path}")
                    print(f"   åŸæ–‡ä»¶: {best_file}")
                    print(f"   Epoch: {best_epoch}, å‡†ç¡®ç‡: {best_acc:.3f}")

                    # åŒæ—¶åˆ›å»ºä¸€ä¸ªç®€å•çš„best.ckpté“¾æ¥
                    simple_best_path = os.path.join(checkpoint_dir, "best.ckpt")
                    if os.path.exists(simple_best_path):
                        os.remove(simple_best_path)
                    shutil.copy2(best_file, simple_best_path)
                    print(f"ğŸ”— [ä¸»è¿›ç¨‹] åŒæ—¶åˆ›å»ºç®€åŒ–é“¾æ¥: {simple_best_path}")

                except Exception as e:
                    print(f"âŒ [ä¸»è¿›ç¨‹] å¤åˆ¶æœ€ä½³æ¨¡å‹å¤±è´¥: {e}")
                    best_model_path = best_file
            else:
                print("âŒ [ä¸»è¿›ç¨‹] æ— æ³•ç¡®å®šæœ€ä½³æ¨¡å‹")
                best_model_path = None
        
        # åˆ›å»ºçŠ¶æ€æ–‡ä»¶ï¼Œå‘ŠçŸ¥å…¶ä»–è¿›ç¨‹ç»“æœ
        if is_distributed:
            status_file = os.path.join(checkpoint_dir, "best_model_status.txt")
            try:
                with open(status_file, 'w') as f:
                    f.write(best_model_path if best_model_path else "None")
                print(f"ğŸ“ [ä¸»è¿›ç¨‹] å·²å†™å…¥çŠ¶æ€æ–‡ä»¶: {status_file}")
            except Exception as e:
                print(f"âš ï¸ [ä¸»è¿›ç¨‹] æ— æ³•å†™å…¥çŠ¶æ€æ–‡ä»¶: {e}")
    
    else:
        # éä¸»è¿›ç¨‹ç­‰å¾…ä¸»è¿›ç¨‹å®Œæˆ
        print(f"â³ [Rank {dist.get_rank()}] ç­‰å¾…ä¸»è¿›ç¨‹å®Œæˆæ¨¡å‹æŸ¥æ‰¾...")
        
        status_file = os.path.join(checkpoint_dir, "best_model_status.txt")
        max_wait_time = 60  # æœ€å¤šç­‰å¾…60ç§’
        wait_time = 0
        
        while wait_time < max_wait_time:
            if os.path.exists(status_file):
                try:
                    with open(status_file, 'r') as f:
                        result = f.read().strip()
                    best_model_path = result if result != "None" else None
                    print(f"ğŸ“– [Rank {dist.get_rank()}] ä»çŠ¶æ€æ–‡ä»¶è¯»å–ç»“æœ: {best_model_path}")
                    break
                except Exception as e:
                    print(f"âš ï¸ [Rank {dist.get_rank()}] è¯»å–çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            
            time.sleep(1)
            wait_time += 1
        
        if wait_time >= max_wait_time:
            print(f"â° [Rank {dist.get_rank()}] ç­‰å¾…è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
            best_model_path = None
    
    # åˆ†å¸ƒå¼åŒæ­¥å±éšœ
    if is_distributed:
        try:
            dist.barrier()
            print(f"ğŸ”„ [Rank {dist.get_rank() if dist.is_initialized() else 'Single'}] åŒæ­¥å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ åˆ†å¸ƒå¼åŒæ­¥å¤±è´¥: {e}")
    
    return best_model_path


def inference_example(model_path: str, image_path: str, config_path: str = 'config.yaml'):
    """æ¨ç†ç¤ºä¾‹"""
    
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    
    # åŠ è½½æ¨¡å‹
    model = ProductClassifier.load_from_checkpoint(model_path, config=config)
    
    # é¢„æµ‹
    result = model.predict_single(image_path)
    
    print("\n" + "="*50)
    print("é¢„æµ‹ç»“æœ")
    print("="*50)
    print(f"å›¾ç‰‡è·¯å¾„: {image_path}")
    print(f"é¢„æµ‹ç±»åˆ«: {result['predicted_class']}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
    print("\nå„ç±»åˆ«æ¦‚ç‡:")
    for class_name, prob in result['probabilities'].items():
        print(f"  {class_name}: {prob:.4f}")
    print("="*50)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PyTorch Lightning å•†å“åˆ†ç±»')

    # åŸºæœ¬å‚æ•°
    parser.add_argument('--config', type=str, default='configs/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='train',
                       choices=['train', 'inference'], help='è¿è¡Œæ¨¡å¼')

    # ç¡¬ä»¶ä¼˜åŒ–å‚æ•°
    parser.add_argument('--auto-optimize', action='store_true', default=True,
                       help='è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶å¹¶ä¼˜åŒ–é…ç½®')
    parser.add_argument('--no-auto-optimize', dest='auto_optimize', action='store_false',
                       help='ç¦ç”¨è‡ªåŠ¨ç¡¬ä»¶ä¼˜åŒ–')
    parser.add_argument('--dynamic-adjustment', action='store_true',
                       help='å¯ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨æ€é…ç½®è°ƒæ•´')
    parser.add_argument('--hardware-tier', type=str,
                       choices=['high_end', 'mid_high', 'mid_range', 'low_end', 'cpu_only'],
                       help='æ‰‹åŠ¨æŒ‡å®šç¡¬ä»¶ç­‰çº§')

    # å¤šGPUå‚æ•°
    parser.add_argument('--multi-gpu', action='store_true', default=True,
                       help='å¯ç”¨å¤šGPUè®­ç»ƒï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--no-multi-gpu', dest='multi_gpu', action='store_false',
                       help='ç¦ç”¨å¤šGPUè®­ç»ƒ')
    parser.add_argument('--strategy', type=str, default=None,
                       choices=['ddp', 'dp', 'deepspeed'],
                       help='å¼ºåˆ¶ä½¿ç”¨çš„å¤šGPUç­–ç•¥')
    parser.add_argument('--gpus', type=int, default=None,
                       help='ä½¿ç”¨çš„GPUæ•°é‡ï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUï¼‰')

    # æ¨ç†å‚æ•°
    parser.add_argument('--model_path', type=str, help='æ¨¡å‹è·¯å¾„ï¼ˆæ¨ç†æ¨¡å¼ï¼‰')
    parser.add_argument('--image_path', type=str, help='å›¾ç‰‡è·¯å¾„ï¼ˆæ¨ç†æ¨¡å¼ï¼‰')
    
    # è®­ç»ƒæ¢å¤å‚æ•°
    parser.add_argument('--ckpt_path', type=str, help='checkpointæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæ¢å¤è®­ç»ƒ')
    
    # åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°ï¼ˆç”±torchrunè‡ªåŠ¨æ·»åŠ ï¼‰
    parser.add_argument('--local-rank', type=int, default=0, help='åˆ†å¸ƒå¼è®­ç»ƒçš„æœ¬åœ°rank')
    parser.add_argument('--local_rank', type=int, default=0, help='åˆ†å¸ƒå¼è®­ç»ƒçš„æœ¬åœ°rank (torchrunå…¼å®¹)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path(args.config).exists():
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    if args.mode == 'train':
        # è®­ç»ƒæ¨¡å¼

        # è®¾ç½®GPUä½¿ç”¨æ•°é‡
        if args.gpus:
            import os
            if args.gpus > torch.cuda.device_count():
                print(f"âš ï¸  æŒ‡å®šçš„GPUæ•°é‡ {args.gpus} è¶…è¿‡å¯ç”¨æ•°é‡ {torch.cuda.device_count()}")
                args.gpus = torch.cuda.device_count()
            # é™åˆ¶å¯è§GPU
            os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, range(args.gpus)))

        # å¦‚æœæŒ‡å®šäº†ç¡¬ä»¶ç­‰çº§ï¼Œä½¿ç”¨å¯¹åº”çš„é…ç½®æ¨¡æ¿
        if args.hardware_tier:
            from ..configs.config_templates import ConfigTemplateGenerator
            generator = ConfigTemplateGenerator()

            template_methods = {
                'high_end': generator.generate_high_end_config,
                'mid_high': generator.generate_mid_high_config,
                'mid_range': generator.generate_mid_range_config,
                'low_end': generator.generate_low_end_config,
                'cpu_only': generator.generate_cpu_only_config
            }

            if args.hardware_tier in template_methods:
                print(f"ä½¿ç”¨ {args.hardware_tier} ç¡¬ä»¶ç­‰çº§çš„é…ç½®æ¨¡æ¿")
                template_config = template_methods[args.hardware_tier]()

                # åˆå¹¶ç”¨æˆ·é…ç½®å’Œæ¨¡æ¿é…ç½®
                for key, value in template_config.items():
                    if key not in config:
                        config[key] = value
                    elif isinstance(value, dict) and isinstance(config[key], dict):
                        config[key].update(value)

        # å¼€å§‹è®­ç»ƒï¼Œä¼ é€’å¤šGPUå‚æ•°
        model, trainer = train_model(
            config,
            auto_optimize=args.auto_optimize,
            multi_gpu=args.multi_gpu,
            force_strategy=args.strategy,
            ckpt_path=args.ckpt_path
        )
        
    elif args.mode == 'inference':
        # æ¨ç†æ¨¡å¼
        if not args.model_path or not args.image_path:
            print("æ¨ç†æ¨¡å¼éœ€è¦æŒ‡å®š --model_path å’Œ --image_path")
            return
        
        inference_example(args.model_path, args.image_path, args.config)


if __name__ == '__main__':
    main()
